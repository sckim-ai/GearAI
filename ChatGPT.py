import streamlit as st
from utils2 import llm_call, prompt_chain_workflow, run_router_workflow
from utils2 import llm_call_async, run_Parallelization, orchestrate_task
from openai.types.responses import ResponseTextDeltaEvent
import asyncio
import json
from agents.mcp import MCPServerStdio
from agents.agent import Agent
import sys

# Windows í˜¸í™˜ì„±
if sys.platform == "win32":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# MCP ì„œë²„ ì„¤ì •
async def setup_mcp_servers():
    servers = []
    
    # mcp.json íŒŒì¼ì—ì„œ ì„¤ì • ì½ê¸°
    with open('mcp.json', 'r') as f:
        config = json.load(f)
    
    # êµ¬ì„±ëœ MCP ì„œë²„ë“¤ì„ ìˆœíšŒ
    for server_name, server_config in config.get('mcpServers', {}).items():
        mcp_server = MCPServerStdio(
            params={
                "command": server_config.get("command"),
                "args": server_config.get("args", [])
            },
            cache_tools_list=True
        )
        await mcp_server.connect()
        servers.append(mcp_server)

    return servers

# ì—ì´ì „íŠ¸ ì„¤ì •
async def setup_agent():
    # ì„œë²„ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ìƒì„±
    mcp_servers = await setup_mcp_servers()
    
    agent = Agent(
        name="Assistant",
        instructions="ë„ˆëŠ” ìœ íŠœë¸Œ ì»¨í…ì¸  ë¶„ì„ì„ ë„ì™€ì£¼ëŠ” ì—ì´ì „íŠ¸ì•¼",
        model="gpt-4o-mini",
        mcp_servers=mcp_servers
    )
    return agent,mcp_servers

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ChatGPT", layout="wide")

# ì„¸ì…˜ ìƒíƒœì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬
SYSTEM_MESSAGE = [
    {
        "role": "system",
        "content": (
            "ì•„ë˜ì˜ ëŒ€í™”ëŠ” ì´ì „ë¶€í„° ì§„í–‰ë˜ì—ˆìœ¼ë©°, í˜„ì¬ê¹Œì§€ ê¸°ë¡ëœ ì‹¤ì œ ëŒ€í™” ë‚´ì—­ì…ë‹ˆë‹¤. "
            "ë”°ë¼ì„œ ì‚¬ìš©ìê°€ ê³¼ê±°ì˜ ë©”ì‹œì§€ë‚˜ ë§¥ë½ì„ ì–¸ê¸‰í•˜ë©´, ì§€ê¸ˆê¹Œì§€ ë°›ì€ ë©”ì‹œì§€ê°€ ì´ì „ ë©”ì‹œì§€ê°€ ì €ì¥ëœ ê¸°ë¡ì„ì„ ì¸ì§€í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤."
        ),
    },
    {
        "role": "assistant",
        "content": (
            "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
        ),
    }    
]

# ì„¸ì…˜ ìƒíƒœì—ì„œ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬
if "messages" not in st.session_state:
    st.session_state.messages = SYSTEM_MESSAGE  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ í¬í•¨


# ì‚¬ì´ë“œë°”ì— OpenAI ëª¨ë¸ ì„¤ì • ì˜µì…˜ ì¶”ê°€
st.sidebar.title("ğŸ”§ ì„¤ì •")
AI_model = st.sidebar.selectbox("AI Agent ì„ íƒ", ["Pure GPT", "Promt chaining", "Routing", "Parallelization", "Orchestrator", "Evaluator optimizer"])
GPT_model = st.sidebar.selectbox("ëª¨ë¸ ì„ íƒ", ["gpt-4o-mini", "gpt-4o"])
temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.7)

# ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ UI
st.title("ğŸ’¬ ChatGPT")

# ê¸°ì¡´ ëŒ€í™” í‘œì‹œ
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥ ë° ì¶œë ¥
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # GPT ì‘ë‹µ ìš”ì²­
    promt = []
    for message in st.session_state.messages:
        role = message["role"]
        content = message["content"]
        promt.append({
            "role": role,
            "content": content
        })
    
    responses = []
    with st.spinner("GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘..."):
        if AI_model == "Pure GPT":
            response = llm_call(
                promt=promt,
                model=GPT_model,            
                temperature=temperature
            )
        
        elif AI_model == "Promt chaining":
            responses = prompt_chain_workflow(promt)
        
        elif AI_model == "Routing":
            responses = run_router_workflow(promt)

        elif AI_model == "Parallelization":
            responses = asyncio.run(run_Parallelization(promt))

        elif AI_model == "Orchestrator":
            response = asyncio.run(orchestrate_task(promt))

    # GPT ì‘ë‹µ ì €ì¥ ë° ì¶œë ¥
    if len(responses) == 0:        
        st.session_state.messages.append({"role": "assistant", "content": response})
        with st.chat_message("assistant"):
            st.markdown(response)
    else:
        for response in responses:
            st.session_state.messages.append({"role": "assistant", "content": response})
            with st.chat_message("assistant"):
                st.markdown(response)
